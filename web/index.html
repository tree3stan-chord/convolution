<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Convolution Reverb Explorer</title>
    <link rel="stylesheet" href="style.css">
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
</head>
<body>
    <div class="container">
        <h1>Convolution Reverb Explorer</h1>
        
        <div id="status" class="status ready">
            <span>Click "Start Live Input" to begin</span>
        </div>

        <div class="controls">
            <div class="control-group">
                <h3>Reverb Parameters</h3>
                <div class="control">
                    <label>Room Size <span class="value" id="roomSizeValue">50</span>%</label>
                    <input type="range" id="roomSize" min="0" max="100" value="50">
                </div>
                <div class="control">
                    <label>Decay Time <span class="value" id="decayTimeValue">2.5</span>s</label>
                    <input type="range" id="decayTime" min="0.1" max="10" step="0.1" value="2.5">
                </div>
                <div class="control">
                    <label>Pre-Delay <span class="value" id="preDelayValue">20</span>ms</label>
                    <input type="range" id="preDelay" min="0" max="100" value="20">
                </div>
            </div>

            <div class="control-group">
                <h3>Tone Control</h3>
                <div class="control">
                    <label>High Frequency Damping <span class="value" id="dampingValue">50</span>%</label>
                    <input type="range" id="damping" min="0" max="100" value="50">
                </div>
                <div class="control">
                    <label>Low Frequency Response <span class="value" id="lowFreqValue">50</span>%</label>
                    <input type="range" id="lowFreq" min="0" max="100" value="50">
                </div>
                <div class="control">
                    <label>Diffusion <span class="value" id="diffusionValue">80</span>%</label>
                    <input type="range" id="diffusion" min="0" max="100" value="80">
                </div>
            </div>

            <div class="control-group">
                <h3>Mix Control</h3>
                <div class="control">
                    <label>Dry/Wet Mix <span class="value" id="mixValue">30</span>%</label>
                    <input type="range" id="mix" min="0" max="100" value="30">
                </div>
                <div class="control">
                    <label>Early Reflections <span class="value" id="earlyReflectionsValue">50</span>%</label>
                    <input type="range" id="earlyReflections" min="0" max="100" value="50">
                </div>
                <div class="control">
                    <label>Impulse Response</label>
                    <select id="impulseResponse">
                        <option value="hall">Concert Hall</option>
                        <option value="cathedral">Cathedral</option>
                        <option value="room">Small Room</option>
                        <option value="plate">Plate Reverb</option>
                        <option value="spring">Spring Reverb</option>
                    </select>
                </div>
            </div>
        </div>

        <div class="action-buttons">
            <button class="button primary" id="liveInputButton">Start Live Input</button>
            <button class="button primary" id="processButton" disabled>Process Audio</button>
            <button class="button secondary" id="loadAudioButton">Load Audio File</button>
            <button class="button secondary" id="resetButton">Reset Parameters</button>
        </div>

        <input type="file" id="audioFileInput" accept="audio/*" style="display: none;">

        <div class="visualizer">
            <canvas id="waveformCanvas"></canvas>
        </div>

        <div class="info">
            <h3>About Convolution Reverb</h3>
            <p>
                This web application demonstrates convolution-based reverb processing using a WebAssembly engine. 
                Click <strong>"Start Live Input"</strong> to process your microphone in real-time with reverb!
            </p>
            <p style="margin-top: 10px;">
                You can also load and process audio files. Adjust the parameters above to explore different reverb characteristics.
                For best results with live input, use headphones to avoid feedback.
            </p>
        </div>
    </div>

    <!-- Load scripts that don't create AudioContext -->
    <script src="convolution_reverb.js"></script>
    <script src="convolution-module.js"></script>
    
    <!-- Main application script -->
    <script>
        // Global state
        let audioContext = null;
        let processor = null;
        let micStream = null;
        let micSource = null;
        let scriptProcessor = null;
        let isProcessingLive = false;
        let currentBuffer = null;
        let currentSource = null;
        let isPlaying = false;

        // Wait for DOM to load
        document.addEventListener('DOMContentLoaded', () => {
            console.log('DOM loaded - setting up UI');
            setupUI();
        });

        // Setup UI without creating AudioContext
        function setupUI() {
            // Setup button handlers
            document.getElementById('liveInputButton').addEventListener('click', toggleLiveInput);
            document.getElementById('processButton').addEventListener('click', toggleProcessAudio);
            document.getElementById('loadAudioButton').addEventListener('click', () => {
                document.getElementById('audioFileInput').click();
            });
            document.getElementById('resetButton').addEventListener('click', resetParameters);
            
            // Setup file input
            document.getElementById('audioFileInput').addEventListener('change', handleFileSelect);
            
            // Setup parameter controls
            setupParameterControls();
            
            // Setup visualizer
            setupVisualizer();
        }

        // Initialize audio system on first user interaction
        async function initializeAudio() {
            if (audioContext) return;
            
            console.log('Initializing audio system...');
            updateStatus('loading', 'Initializing audio system...');
            
            try {
                // Create AudioContext
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                console.log('AudioContext created, state:', audioContext.state);
                
                // Initialize processor
                processor = new ConvolutionProcessor();
                await processor.initialize('./', audioContext.sampleRate);
                console.log('Processor initialized');
                
                // Apply current parameter values
                applyParametersToProcessor();
                
                return true;
            } catch (error) {
                console.error('Failed to initialize audio:', error);
                updateStatus('error', 'Failed to initialize audio: ' + error.message);
                return false;
            }
        }

        // Toggle live input
        async function toggleLiveInput() {
            if (isProcessingLive) {
                stopLiveInput();
            } else {
                await startLiveInput();
            }
        }

        // Start live input
        async function startLiveInput() {
            console.log('Starting live input...');
            
            // Initialize audio if needed
            if (!audioContext) {
                const success = await initializeAudio();
                if (!success) return;
            }
            
            // Resume context if needed
            if (audioContext.state === 'suspended') {
                await audioContext.resume();
            }
            
            try {
                updateStatus('loading', 'Requesting microphone access...');
                
                // Request microphone
                micStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false
                    }
                });
                
                console.log('Microphone access granted');
                
                // Create audio nodes
                micSource = audioContext.createMediaStreamSource(micStream);
                scriptProcessor = audioContext.createScriptProcessor(2048, 1, 1);
                
                // Process audio
                scriptProcessor.onaudioprocess = (e) => {
                    if (!isProcessingLive || !processor) return;
                    
                    const input = e.inputBuffer.getChannelData(0);
                    const output = e.outputBuffer.getChannelData(0);
                    
                    try {
                        const processed = processor.processAudio(input);
                        output.set(processed.subarray(0, output.length));
                        updateVisualizer(output);
                    } catch (error) {
                        output.set(input); // Passthrough on error
                    }
                };
                
                // Connect nodes
                micSource.connect(scriptProcessor);
                scriptProcessor.connect(audioContext.destination);
                
                isProcessingLive = true;
                updateStatus('ready', 'Processing live input with reverb');
                document.getElementById('liveInputButton').textContent = 'Stop Live Input';
                document.getElementById('liveInputButton').classList.add('active');
                document.getElementById('processButton').disabled = true;
                
            } catch (error) {
                console.error('Microphone error:', error);
                if (error.name === 'NotAllowedError') {
                    updateStatus('error', 'Microphone access denied. Please allow microphone access.');
                } else if (error.name === 'NotFoundError') {
                    updateStatus('error', 'No microphone found.');
                } else {
                    updateStatus('error', 'Error: ' + error.message);
                }
            }
        }

        // Stop live input
        function stopLiveInput() {
            isProcessingLive = false;
            
            if (scriptProcessor) {
                scriptProcessor.disconnect();
                scriptProcessor = null;
            }
            
            if (micSource) {
                micSource.disconnect();
                micSource = null;
            }
            
            if (micStream) {
                micStream.getTracks().forEach(track => track.stop());
                micStream = null;
            }
            
            updateStatus('ready', 'Live input stopped');
            document.getElementById('liveInputButton').textContent = 'Start Live Input';
            document.getElementById('liveInputButton').classList.remove('active');
            document.getElementById('processButton').disabled = currentBuffer == null;
        }

        // Handle file selection
        async function handleFileSelect(e) {
            const file = e.target.files[0];
            if (!file) return;
            
            // Initialize audio if needed
            if (!audioContext) {
                const success = await initializeAudio();
                if (!success) return;
            }
            
            try {
                updateStatus('loading', 'Loading audio file...');
                const arrayBuffer = await file.arrayBuffer();
                currentBuffer = await audioContext.decodeAudioData(arrayBuffer);
                
                updateStatus('ready', `Loaded: ${file.name}`);
                document.getElementById('processButton').disabled = false;
                
                drawWaveform(currentBuffer);
            } catch (error) {
                console.error('File load error:', error);
                updateStatus('error', 'Error loading file');
            }
        }

        // Toggle process audio
        function toggleProcessAudio() {
            if (isPlaying) {
                stopAudio();
            } else {
                processAudioFile();
            }
        }

        // Process audio file
        async function processAudioFile() {
            if (!currentBuffer || !processor) return;
            
            try {
                updateStatus('loading', 'Processing audio...');
                
                const input = currentBuffer.getChannelData(0);
                const output = processor.processAudio(input);
                
                const outputBuffer = audioContext.createBuffer(1, output.length, currentBuffer.sampleRate);
                outputBuffer.getChannelData(0).set(output);
                
                playBuffer(outputBuffer);
                updateStatus('ready', 'Playing processed audio');
            } catch (error) {
                console.error('Processing error:', error);
                updateStatus('error', 'Error processing audio');
            }
        }

        // Play buffer
        function playBuffer(buffer) {
            stopAudio();
            
            currentSource = audioContext.createBufferSource();
            currentSource.buffer = buffer;
            currentSource.connect(audioContext.destination);
            currentSource.onended = () => {
                isPlaying = false;
                document.getElementById('processButton').textContent = 'Process Audio';
            };
            
            currentSource.start(0);
            isPlaying = true;
            document.getElementById('processButton').textContent = 'Stop';
        }

        // Stop audio
        function stopAudio() {
            if (currentSource) {
                currentSource.stop();
                currentSource.disconnect();
                currentSource = null;
            }
            isPlaying = false;
            document.getElementById('processButton').textContent = 'Process Audio';
        }

        // Setup parameter controls
        function setupParameterControls() {
            const params = ['roomSize', 'decayTime', 'preDelay', 'damping', 'lowFreq', 'diffusion', 'mix', 'earlyReflections'];
            
            params.forEach(param => {
                const slider = document.getElementById(param);
                const value = document.getElementById(param + 'Value');
                
                if (slider && value) {
                    slider.addEventListener('input', (e) => {
                        value.textContent = e.target.value;
                        if (processor) {
                            processor.setParameter(param, parseFloat(e.target.value));
                        }
                    });
                }
            });
            
            const irSelect = document.getElementById('impulseResponse');
            if (irSelect) {
                irSelect.addEventListener('change', (e) => {
                    if (processor) {
                        processor.setImpulseResponseType(e.target.value);
                    }
                });
            }
        }

        // Apply parameters to processor
        function applyParametersToProcessor() {
            if (!processor) return;
            
            const params = ['roomSize', 'decayTime', 'preDelay', 'damping', 'lowFreq', 'diffusion', 'mix', 'earlyReflections'];
            params.forEach(param => {
                const slider = document.getElementById(param);
                if (slider) {
                    processor.setParameter(param, parseFloat(slider.value));
                }
            });
        }

        // Reset parameters
        function resetParameters() {
            const defaults = {
                roomSize: 50,
                decayTime: 2.5,
                preDelay: 20,
                damping: 50,
                lowFreq: 50,
                diffusion: 80,
                mix: 30,
                earlyReflections: 50
            };
            
            Object.entries(defaults).forEach(([param, value]) => {
                const slider = document.getElementById(param);
                const display = document.getElementById(param + 'Value');
                if (slider && display) {
                    slider.value = value;
                    display.textContent = value;
                    if (processor) {
                        processor.setParameter(param, value);
                    }
                }
            });
        }

        // Update status
        function updateStatus(type, message) {
            const status = document.getElementById('status');
            status.className = 'status ' + type;
            status.textContent = message;
        }

        // Setup visualizer
        function setupVisualizer() {
            const canvas = document.getElementById('waveformCanvas');
            const ctx = canvas.getContext('2d');
            
            function resize() {
                canvas.width = canvas.offsetWidth;
                canvas.height = canvas.offsetHeight;
                drawEmptyWaveform();
            }
            
            window.addEventListener('resize', resize);
            resize();
        }

        // Draw empty waveform
        function drawEmptyWaveform() {
            const canvas = document.getElementById('waveformCanvas');
            const ctx = canvas.getContext('2d');
            
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.strokeStyle = '#90e0ef';
            ctx.lineWidth = 1;
            ctx.beginPath();
            ctx.moveTo(0, canvas.height / 2);
            ctx.lineTo(canvas.width, canvas.height / 2);
            ctx.stroke();
        }

        // Update visualizer
        function updateVisualizer(data) {
            const canvas = document.getElementById('waveformCanvas');
            const ctx = canvas.getContext('2d');
            
            ctx.fillStyle = 'rgba(0, 0, 0, 0.1)';
            ctx.fillRect(0, 0, canvas.width, canvas.height);
            
            ctx.strokeStyle = '#90e0ef';
            ctx.lineWidth = 2;
            ctx.beginPath();
            
            const sliceWidth = canvas.width / data.length;
            let x = 0;
            
            for (let i = 0; i < data.length; i++) {
                const y = (1 + data[i]) * canvas.height / 2;
                if (i === 0) {
                    ctx.moveTo(x, y);
                } else {
                    ctx.lineTo(x, y);
                }
                x += sliceWidth;
            }
            
            ctx.stroke();
        }

        // Draw waveform
        function drawWaveform(buffer) {
            const canvas = document.getElementById('waveformCanvas');
            const ctx = canvas.getContext('2d');
            const data = buffer.getChannelData(0);
            
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.strokeStyle = '#90e0ef';
            ctx.lineWidth = 2;
            
            const step = Math.ceil(data.length / canvas.width);
            ctx.beginPath();
            
            for (let i = 0; i < canvas.width; i++) {
                const min = Math.min(...data.slice(i * step, (i + 1) * step));
                const max = Math.max(...data.slice(i * step, (i + 1) * step));
                
                const yMin = (1 - min) * canvas.height / 2;
                const yMax = (1 - max) * canvas.height / 2;
                
                if (i === 0) {
                    ctx.moveTo(i, (yMin + yMax) / 2);
                } else {
                    ctx.lineTo(i, yMin);
                    ctx.lineTo(i, yMax);
                }
            }
            
            ctx.stroke();
        }
    </script>
</body>
</html>