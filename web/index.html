<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Convolution Reverb Playground</title>
    <link rel="stylesheet" href="style.css">
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
</head>
<body>
    <div class="container">
        <h1>ü§∑‚Äç‚ôÇÔ∏è convolution ü§∑‚Äç‚ôÇÔ∏è</h1>
        
        <div id="status" class="status ready">
            <span>Click "Start Live Input" to begin</span>
        </div>

        <div class="controls">
            <div class="control-group">
                <h3>Reverb Parameters</h3>
                <div class="control">
                    <label>Room Size <span class="value" id="roomSizeValue">50</span>%</label>
                    <input type="range" id="roomSize" min="0" max="100" value="50">
                </div>
                <div class="control">
                    <label>Decay Time <span class="value" id="decayTimeValue">2.5</span>s</label>
                    <input type="range" id="decayTime" min="0.1" max="10" step="0.1" value="2.5">
                </div>
                <div class="control">
                    <label>Pre-Delay <span class="value" id="preDelayValue">20</span>ms</label>
                    <input type="range" id="preDelay" min="0" max="100" value="20">
                </div>
            </div>

            <div class="control-group">
                <h3>Tone Control</h3>
                <div class="control">
                    <label>High Frequency Damping <span class="value" id="dampingValue">50</span>%</label>
                    <input type="range" id="damping" min="0" max="100" value="50">
                </div>
                <div class="control">
                    <label>Low Frequency Response <span class="value" id="lowFreqValue">50</span>%</label>
                    <input type="range" id="lowFreq" min="0" max="100" value="50">
                </div>
                <div class="control">
                    <label>Diffusion <span class="value" id="diffusionValue">80</span>%</label>
                    <input type="range" id="diffusion" min="0" max="100" value="80">
                </div>
            </div>

            <div class="control-group">
                <h3>Mix Control</h3>
                <div class="control">
                    <label>Dry/Wet Mix <span class="value" id="mixValue">30</span>%</label>
                    <input type="range" id="mix" min="0" max="100" value="30">
                </div>
                <div class="control">
                    <label>Early Reflections <span class="value" id="earlyReflectionsValue">50</span>%</label>
                    <input type="range" id="earlyReflections" min="0" max="100" value="50">
                </div>
                <div class="control">
                    <label>Impulse Response</label>
                    <select id="impulseResponse">
                        <option value="hall">Concert Hall</option>
                        <option value="cathedral">Cathedral</option>
                        <option value="room">Small Room</option>
                        <option value="plate">Plate Reverb</option>
                        <option value="spring">Spring Reverb</option>
                    </select>
                </div>
            </div>
        </div>

        <div class="action-buttons">
            <button class="button primary" id="liveInputButton">Start Live Input</button>
            <button class="button primary" id="processButton" disabled>Process Audio</button>
            <button class="button secondary" id="loadAudioButton">Load Audio File</button>
            <button class="button secondary" id="resetButton">Reset Parameters</button>
        </div>

        <input type="file" id="audioFileInput" accept="audio/*" style="display: none;">

        <div class="visualizer">
            <canvas id="waveformCanvas"></canvas>
        </div>

        <div class="info">
            <h3>About Convolution Reverb</h3>
            <p>
                This web application demonstrates convolution-based reverb processing using a WebAssembly engine. 
                Click <strong>"Start Live Input"</strong> to process your microphone in real-time with reverb!
            </p>
            <p style="margin-top: 10px;">
                You can also load and process audio files. Adjust the parameters above to explore different reverb characteristics.
                For best results with live input, use headphones to avoid feedback.
            </p>
            <details style="margin-top: 15px;">
                <summary style="cursor: pointer; color: #90e0ef;">Technical Details</summary>
                <div style="margin-top: 10px; padding: 10px; background: rgba(255,255,255,0.05); border-radius: 8px;">
                    <p><strong>Engine:</strong> <span id="engineType">Checking...</span></p>
                    <p><strong>Sample Rate:</strong> <span id="sampleRate">-</span> Hz</p>
                    <p><strong>Processing:</strong> <span id="processingType">-</span></p>
                    <p><strong>Latency:</strong> <span id="latency">-</span> ms</p>
                    <p style="margin-top: 8px; font-size: 0.9em; opacity: 0.8;">
                        Note: The current implementation uses a simplified C convolution algorithm compiled to WebAssembly. 
                        The original Fortran code requires specialized toolchain support for WASM compilation.
                    </p>
                </div>
            </details>
        </div>
    </div>

    <!-- Load scripts that don't create AudioContext -->
    <script src="convolution_reverb.js"></script>
    <script src="convolution-module.js"></script>
    
    <!-- Main application script -->
    <script>
        // Global state
        let audioContext = null;
        let processor = null;
        let micStream = null;
        let micSource = null;
        let scriptProcessor = null;
        let isProcessingLive = false;
        let currentBuffer = null;
        let currentSource = null;
        let isPlaying = false;
        let analyser = null;
        let animationId = null;

        // Wait for DOM to load
        document.addEventListener('DOMContentLoaded', () => {
            console.log('DOM loaded - setting up UI');
            setupUI();
        });

        // Setup UI without creating AudioContext
        function setupUI() {
            // Setup button handlers
            document.getElementById('liveInputButton').addEventListener('click', toggleLiveInput);
            document.getElementById('processButton').addEventListener('click', toggleProcessAudio);
            document.getElementById('loadAudioButton').addEventListener('click', () => {
                document.getElementById('audioFileInput').click();
            });
            document.getElementById('resetButton').addEventListener('click', resetParameters);
            
            // Setup file input
            document.getElementById('audioFileInput').addEventListener('change', handleFileSelect);
            
            // Setup parameter controls
            setupParameterControls();
            
            // Setup visualizer
            setupVisualizer();
        }

        // Initialize audio system on first user interaction
        async function initializeAudio() {
            if (audioContext) return;
            
            console.log('Initializing audio system...');
            updateStatus('loading', 'Initializing audio system...');
            
            try {
                // Create AudioContext
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                console.log('AudioContext created, state:', audioContext.state);
                
                // Update technical details
                document.getElementById('sampleRate').textContent = audioContext.sampleRate;
                document.getElementById('engineType').textContent = 'C/WebAssembly (Simplified)';
                
                // Initialize processor
                processor = new ConvolutionProcessor();
                await processor.initialize('./', audioContext.sampleRate);
                console.log('Processor initialized');
                
                // Check what version we're using
                if (processor.getVersion) {
                    console.log('Engine version:', processor.getVersion());
                }
                
                // Apply current parameter values
                applyParametersToProcessor();
                
                return true;
            } catch (error) {
                console.error('Failed to initialize audio:', error);
                updateStatus('error', 'Failed to initialize audio: ' + error.message);
                return false;
            }
        }

        // Toggle live input
        async function toggleLiveInput() {
            if (isProcessingLive) {
                stopLiveInput();
            } else {
                await startLiveInput();
            }
        }

        // Start live input
        async function startLiveInput() {
            console.log('Starting live input...');
            
            // Initialize audio if needed
            if (!audioContext) {
                const success = await initializeAudio();
                if (!success) return;
            }
            
            // Resume context if needed
            if (audioContext.state === 'suspended') {
                await audioContext.resume();
            }
            
            try {
                updateStatus('loading', 'Requesting microphone access...');
                
                // Request microphone
                micStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false
                    }
                });
                
                console.log('Microphone access granted');
                
                // Create audio nodes
                micSource = audioContext.createMediaStreamSource(micStream);
                scriptProcessor = audioContext.createScriptProcessor(2048, 1, 1);
                
                // Process audio
                scriptProcessor.onaudioprocess = (e) => {
                    if (!isProcessingLive || !processor) return;
                    
                    const input = e.inputBuffer.getChannelData(0);
                    const output = e.outputBuffer.getChannelData(0);
                    
                    try {
                        const processed = processor.processAudio(input);
                        output.set(processed.subarray(0, output.length));
                    } catch (error) {
                        output.set(input); // Passthrough on error
                    }
                };
                
                // Create analyser for visualization
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;
                analyser.smoothingTimeConstant = 0.8;
                
                // Connect nodes
                micSource.connect(scriptProcessor);
                scriptProcessor.connect(audioContext.destination);
                scriptProcessor.connect(analyser);
                
                // Update technical details
                const bufferSize = scriptProcessor.bufferSize;
                const latencyMs = (bufferSize / audioContext.sampleRate) * 1000;
                document.getElementById('processingType').textContent = 'ScriptProcessor (2048 samples)';
                document.getElementById('latency').textContent = latencyMs.toFixed(1);
                
                // Start visualization
                startLiveVisualization();
                
                isProcessingLive = true;
                updateStatus('ready', 'Processing live input with reverb');
                document.getElementById('liveInputButton').textContent = 'Stop Live Input';
                document.getElementById('liveInputButton').classList.add('active');
                document.getElementById('processButton').disabled = true;
                
            } catch (error) {
                console.error('Microphone error:', error);
                if (error.name === 'NotAllowedError') {
                    updateStatus('error', 'Microphone access denied. Please allow microphone access.');
                } else if (error.name === 'NotFoundError') {
                    updateStatus('error', 'No microphone found.');
                } else {
                    updateStatus('error', 'Error: ' + error.message);
                }
            }
        }

        // Stop live input
        function stopLiveInput() {
            isProcessingLive = false;
            
            stopVisualization();
            
            if (analyser) {
                analyser.disconnect();
                analyser = null;
            }
            
            if (scriptProcessor) {
                scriptProcessor.disconnect();
                scriptProcessor = null;
            }
            
            if (micSource) {
                micSource.disconnect();
                micSource = null;
            }
            
            if (micStream) {
                micStream.getTracks().forEach(track => track.stop());
                micStream = null;
            }
            
            updateStatus('ready', 'Live input stopped');
            document.getElementById('liveInputButton').textContent = 'Start Live Input';
            document.getElementById('liveInputButton').classList.remove('active');
            document.getElementById('processButton').disabled = currentBuffer == null;
            
            // Restart idle animation
            animateIdleWaveform();
        }

        // Handle file selection
        async function handleFileSelect(e) {
            const file = e.target.files[0];
            if (!file) return;
            
            // Initialize audio if needed
            if (!audioContext) {
                const success = await initializeAudio();
                if (!success) return;
            }
            
            try {
                updateStatus('loading', 'Loading audio file...');
                const arrayBuffer = await file.arrayBuffer();
                currentBuffer = await audioContext.decodeAudioData(arrayBuffer);
                
                updateStatus('ready', `Loaded: ${file.name}`);
                document.getElementById('processButton').disabled = false;
                
                drawWaveform(currentBuffer);
            } catch (error) {
                console.error('File load error:', error);
                updateStatus('error', 'Error loading file');
            }
        }

        // Toggle process audio
        function toggleProcessAudio() {
            if (isPlaying) {
                stopAudio();
            } else {
                processAudioFile();
            }
        }

        // Process audio file
        async function processAudioFile() {
            if (!currentBuffer || !processor) return;
            
            try {
                updateStatus('loading', 'Processing audio...');
                
                const input = currentBuffer.getChannelData(0);
                const output = processor.processAudio(input);
                
                const outputBuffer = audioContext.createBuffer(1, output.length, currentBuffer.sampleRate);
                outputBuffer.getChannelData(0).set(output);
                
                playBuffer(outputBuffer);
                updateStatus('ready', 'Playing processed audio');
            } catch (error) {
                console.error('Processing error:', error);
                updateStatus('error', 'Error processing audio');
            }
        }

        // Play buffer
        function playBuffer(buffer) {
            stopAudio();
            
            // Create analyser for visualization
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 2048;
            analyser.smoothingTimeConstant = 0.8;
            
            currentSource = audioContext.createBufferSource();
            currentSource.buffer = buffer;
            currentSource.connect(analyser);
            analyser.connect(audioContext.destination);
            
            currentSource.onended = () => {
                isPlaying = false;
                document.getElementById('processButton').textContent = 'Process Audio';
                stopVisualization();
                animateIdleWaveform();
            };
            
            currentSource.start(0);
            isPlaying = true;
            document.getElementById('processButton').textContent = 'Stop';
            
            // Start visualization
            startPlaybackVisualization();
        }

        // Stop audio
        function stopAudio() {
            stopVisualization();
            
            if (analyser) {
                analyser.disconnect();
                analyser = null;
            }
            
            if (currentSource) {
                currentSource.stop();
                currentSource.disconnect();
                currentSource = null;
            }
            isPlaying = false;
            document.getElementById('processButton').textContent = 'Process Audio';
            
            // Restart idle animation
            animateIdleWaveform();
        }

        // Setup parameter controls
        function setupParameterControls() {
            const params = ['roomSize', 'decayTime', 'preDelay', 'damping', 'lowFreq', 'diffusion', 'mix', 'earlyReflections'];
            
            params.forEach(param => {
                const slider = document.getElementById(param);
                const value = document.getElementById(param + 'Value');
                
                if (slider && value) {
                    slider.addEventListener('input', (e) => {
                        const val = parseFloat(e.target.value);
                        value.textContent = val;
                        
                        // Log parameter changes for debugging
                        console.log(`Setting ${param} to ${val}`);
                        
                        if (processor) {
                            processor.setParameter(param, val);
                            
                            // If we're processing live, the changes should apply immediately
                            if (isProcessingLive) {
                                console.log(`Live update: ${param} = ${val}`);
                            }
                        }
                    });
                }
            });
            
            const irSelect = document.getElementById('impulseResponse');
            if (irSelect) {
                irSelect.addEventListener('change', (e) => {
                    console.log(`Setting IR type to ${e.target.value}`);
                    if (processor) {
                        processor.setImpulseResponseType(e.target.value);
                    }
                });
            }
        }

        // Apply parameters to processor
        function applyParametersToProcessor() {
            if (!processor) return;
            
            const params = ['roomSize', 'decayTime', 'preDelay', 'damping', 'lowFreq', 'diffusion', 'mix', 'earlyReflections'];
            params.forEach(param => {
                const slider = document.getElementById(param);
                if (slider) {
                    processor.setParameter(param, parseFloat(slider.value));
                }
            });
        }

        // Reset parameters
        function resetParameters() {
            const defaults = {
                roomSize: 50,
                decayTime: 2.5,
                preDelay: 20,
                damping: 50,
                lowFreq: 50,
                diffusion: 80,
                mix: 30,
                earlyReflections: 50
            };
            
            Object.entries(defaults).forEach(([param, value]) => {
                const slider = document.getElementById(param);
                const display = document.getElementById(param + 'Value');
                if (slider && display) {
                    slider.value = value;
                    display.textContent = value;
                    if (processor) {
                        processor.setParameter(param, value);
                    }
                }
            });
        }

        // Update status
        function updateStatus(type, message) {
            const status = document.getElementById('status');
            status.className = 'status ' + type;
            status.textContent = message;
        }

        // Setup visualizer
        function setupVisualizer() {
            const canvas = document.getElementById('waveformCanvas');
            const ctx = canvas.getContext('2d');
            
            function resize() {
                canvas.width = canvas.offsetWidth;
                canvas.height = canvas.offsetHeight;
                drawEmptyWaveform();
            }
            
            window.addEventListener('resize', resize);
            resize();
            
            // Start idle animation
            animateIdleWaveform();
        }

        // Draw empty waveform
        function drawEmptyWaveform() {
            const canvas = document.getElementById('waveformCanvas');
            const ctx = canvas.getContext('2d');
            
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.strokeStyle = '#90e0ef';
            ctx.lineWidth = 1;
            ctx.beginPath();
            ctx.moveTo(0, canvas.height / 2);
            ctx.lineTo(canvas.width, canvas.height / 2);
            ctx.stroke();
        }

        // Start live visualization
        function startLiveVisualization() {
            stopVisualization();
            
            const canvas = document.getElementById('waveformCanvas');
            const ctx = canvas.getContext('2d');
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Float32Array(bufferLength);
            
            function draw() {
                animationId = requestAnimationFrame(draw);
                
                analyser.getFloatTimeDomainData(dataArray);
                
                // Clear with fade effect
                ctx.fillStyle = 'rgba(0, 0, 0, 0.1)';
                ctx.fillRect(0, 0, canvas.width, canvas.height);
                
                // Draw waveform
                ctx.lineWidth = 2;
                ctx.strokeStyle = '#90e0ef';
                ctx.beginPath();
                
                const sliceWidth = canvas.width / bufferLength;
                let x = 0;
                
                for (let i = 0; i < bufferLength; i++) {
                    const v = dataArray[i];
                    const y = (v + 1) / 2 * canvas.height;
                    
                    if (i === 0) {
                        ctx.moveTo(x, y);
                    } else {
                        ctx.lineTo(x, y);
                    }
                    
                    x += sliceWidth;
                }
                
                ctx.stroke();
                
                // Add glow effect
                ctx.shadowBlur = 15;
                ctx.shadowColor = '#90e0ef';
                ctx.stroke();
                ctx.shadowBlur = 0;
            }
            
            draw();
        }
        
        // Start playback visualization
        function startPlaybackVisualization() {
            stopVisualization();
            
            const canvas = document.getElementById('waveformCanvas');
            const ctx = canvas.getContext('2d');
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            
            function draw() {
                animationId = requestAnimationFrame(draw);
                
                analyser.getByteTimeDomainData(dataArray);
                
                // Clear canvas
                ctx.fillStyle = 'rgba(0, 0, 0, 0.05)';
                ctx.fillRect(0, 0, canvas.width, canvas.height);
                
                // Draw waveform
                ctx.lineWidth = 2;
                ctx.strokeStyle = '#90e0ef';
                ctx.beginPath();
                
                const sliceWidth = canvas.width / bufferLength;
                let x = 0;
                
                for (let i = 0; i < bufferLength; i++) {
                    const v = dataArray[i] / 128.0;
                    const y = v * canvas.height / 2;
                    
                    if (i === 0) {
                        ctx.moveTo(x, y);
                    } else {
                        ctx.lineTo(x, y);
                    }
                    
                    x += sliceWidth;
                }
                
                ctx.stroke();
                
                // Add center line
                ctx.strokeStyle = 'rgba(144, 224, 239, 0.2)';
                ctx.lineWidth = 1;
                ctx.beginPath();
                ctx.moveTo(0, canvas.height / 2);
                ctx.lineTo(canvas.width, canvas.height / 2);
                ctx.stroke();
            }
            
            draw();
        }
        
        // Stop visualization
        function stopVisualization() {
            if (animationId) {
                cancelAnimationFrame(animationId);
                animationId = null;
            }
        }
        
        // Update visualizer (remove old function)
        function updateVisualizer(data) {
            // This function is no longer needed as we use analyser
        }

        // Draw waveform
        function drawWaveform(buffer) {
            const canvas = document.getElementById('waveformCanvas');
            const ctx = canvas.getContext('2d');
            const data = buffer.getChannelData(0);
            
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            // Draw gradient background
            const gradient = ctx.createLinearGradient(0, 0, 0, canvas.height);
            gradient.addColorStop(0, 'rgba(144, 224, 239, 0.1)');
            gradient.addColorStop(0.5, 'rgba(144, 224, 239, 0.05)');
            gradient.addColorStop(1, 'rgba(144, 224, 239, 0.1)');
            ctx.fillStyle = gradient;
            ctx.fillRect(0, 0, canvas.width, canvas.height);
            
            ctx.strokeStyle = '#90e0ef';
            ctx.lineWidth = 2;
            
            const step = Math.ceil(data.length / canvas.width);
            ctx.beginPath();
            
            for (let i = 0; i < canvas.width; i++) {
                const min = Math.min(...data.slice(i * step, (i + 1) * step));
                const max = Math.max(...data.slice(i * step, (i + 1) * step));
                
                const yMin = (1 - min) * canvas.height / 2;
                const yMax = (1 - max) * canvas.height / 2;
                
                if (i === 0) {
                    ctx.moveTo(i, (yMin + yMax) / 2);
                } else {
                    ctx.lineTo(i, yMin);
                    ctx.lineTo(i, yMax);
                }
            }
            
            ctx.stroke();
        }
        
        // Animated idle waveform
        function animateIdleWaveform() {
            stopVisualization();
            
            const canvas = document.getElementById('waveformCanvas');
            const ctx = canvas.getContext('2d');
            let phase = 0;
            
            function draw() {
                if (isProcessingLive || isPlaying) {
                    return;
                }
                
                animationId = requestAnimationFrame(draw);
                
                ctx.fillStyle = 'rgba(15, 15, 26, 0.1)';
                ctx.fillRect(0, 0, canvas.width, canvas.height);
                
                // Draw animated sine wave
                ctx.strokeStyle = 'rgba(144, 224, 239, 0.3)';
                ctx.lineWidth = 2;
                ctx.beginPath();
                
                for (let x = 0; x < canvas.width; x++) {
                    const y = canvas.height / 2 + 
                             Math.sin((x / canvas.width) * Math.PI * 4 + phase) * 20 * 
                             Math.sin((x / canvas.width) * Math.PI);
                    
                    if (x === 0) {
                        ctx.moveTo(x, y);
                    } else {
                        ctx.lineTo(x, y);
                    }
                }
                
                ctx.stroke();
                
                // Add center line
                ctx.strokeStyle = 'rgba(144, 224, 239, 0.2)';
                ctx.lineWidth = 1;
                ctx.beginPath();
                ctx.moveTo(0, canvas.height / 2);
                ctx.lineTo(canvas.width, canvas.height / 2);
                ctx.stroke();
                
                phase += 0.05;
            }
            
            draw();
        }
    </script>
</body>
</html>